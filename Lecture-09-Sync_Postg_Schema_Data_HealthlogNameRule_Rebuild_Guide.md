Absolutely, John — here’s your **video demo script**, broken into **Part 1 (Setup)** and **Part 2 (Lecture 09 Demo)**. You can use this as your **narration outline** or paste directly into `Lecture-09-Setup-And-Demo.md` for your GitHub repo.

---

## 🎥 **Lecture 09: ja_db_02 Rebuild & Automation Demo**

---

## 🧱 **PART 1: Setup & Rebuild on a New Device**

### 🛠️ Initial Setup Checklist
To rebuild this project from a fresh clone, follow these steps:

1. ✅ **Clone the Repo**
```bash
git clone https://github.com/wolfmib/ja_db_02.git
cd ja_db_02
```

2. ✅ **Create a `.env` File**  
Fill in:
```env
GITHUB_USER=wolfmib
GITHUB_TOKEN=github_pat_xxxxxxxxxxxx
GITHUB_REPO=https://github.com/wolfmib/ja_db_02.git
```

3. ✅ **Create PostgreSQL Tables**  
Run the SQL inside `CreateTable.md`:
- `clients`
- `client_actions`
- `client_domains`
- `client_info`

4. ✅ **Set Up Database Role**  
Run SQL from `CreateRole.md` to:
- Create `ja_db` user
- Grant read access to all public tables

5. ✅ **Place Google API Credential File**
Put your credential file here:
```bash
client_secret_542560XXXXXXXXXXXXX87q4p5.apps.googleusercontent.com.json
```

6. ✅ **Run Auth Script to Generate Token**
> Needs to be run **locally**, not in Docker (it opens a browser).

```bash
python3 CreateGoogleCredent.py
```

This generates `token.json` for Google Drive API access.

7. ✅ **Set Up Superset**
- Log into PostgreSQL and create the Superset user (`bi_superset`)
- Log into Superset UI at http://localhost:8088
  - Username: `admin`
  - Password: `admin123!` (or what you set)
- Connect to PostgreSQL and add datasets

8. ✅ **Recreate the View**
To support Superset queries, recreate the view:
```sql
CREATE OR REPLACE VIEW public.v_client_actions_with_names AS ...
```

(Replace `...` with your join logic)

9. ✅ **Debug Local Testing**
If testing locally (not in Docker), use container IP instead of `localhost`:
```bash
docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' ja_db_02-db-1
```

Use that IP in your DB connection string for testing outside the container.

10. ✅ **Understand the Role of `health_helper_server.json`**
This file is generated by `helper-02` (syncing clients.json → PostgreSQL).
Keep it in `log/` — it tracks sync status.

11. ✅ **Fix Health + Log Upload Paths**
We patched the log paths so all health logs are written to `log/`, not the root.

12. ✅ **Verify View Renamed for Superset**
This ensures charts in Superset reflect correct client name mappings.

---

## 🧪 **PART 2: Lecture 09 — Schema & Health Automation Demo**

### 🔄 Overview

We added a 3rd automation helper to export **PostgreSQL schema & data** every 30 mins, and to maintain a clean, timestamped health log system.

---

### 🌐 Features Demoed

#### 1. ✅ Added Third Helper
- `automation_python_ja_db_02_autosyncbackto_googledrive_helper.py`
- Auto-detects all base tables
- Serializes to:
  - `client_info_data.json`
  - `client_info_schema.json`
  - `...`

#### 2. ✅ Standardized Log Naming
- Format:  
  `health_<project>_<scope>_<instance>_<timestamp>.json`
- Example:  
  `health_ja_db_02_automation_autocommit_helper01_20250425-180000.json`

#### 3. ✅ Centralized Metadata Extraction
- Logic moved to `ja_tool.py`:
  - hostname
  - IP
  - OS
  - script name
- Used in all 3 helpers

#### 4. ✅ Bash-Based Multi-Helper Docker Launch
```yaml
command: bash -c "
  python3 automation_python_ja_db_02_autocommit_helper_server.py &
  python3 automation_python_ja_sync_action_helper_server.py &
  python3 automation_python_ja_db_02_autosyncbackto_googledrive_helper.py &
  wait
"
```

- 3 scripts run concurrently
- Auto-restart on failure

---

### 📚 Live Demo Tips

To run each manually:
```bash
docker exec -it ja_db_02-automation-1 bash
python3 automation_python_ja_db_02_autocommit_helper_server.py
python3 automation_python_ja_sync_action_helper_server.py
python3 automation_python_ja_db_02_autosyncbackto_googledrive_helper.py
```

Check:

| Output                | Where to Look           |
|----------------------|-------------------------|
| Health logs          | `GoogleDrive/javis_shell/log/` |
| Schema/data exports  | `GoogleDrive/javis_shell/`      |
| Git commit log push  | GitHub commits tab      |

---

### 📊 Results

- ✅ Full health traceability (every 1 min)
- ✅ Git auto-push from container (every 1440 mins)
- ✅ Clean `.json` snapshot of all tables every 30 mins
- ✅ Ready for Superset dashboards

---

Let me know when you want a `Lecture-10.md` or a new GitHub badge for this 🎓📦💾🔥
